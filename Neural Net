import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.datasets import mnist

# If you face any issue to run the code in GPU...,
physical_devices = tf.config.list_physical_devices('GPU')
try:
  tf.config.experimental.set_memory_growth(physical_devices[0], True)
except:
  pass

(x_train,y_train),(x_test,y_test) = mnist.load_data()
print('x_train: ',x_train.shape)
print('x_test: ', x_test.shape)

x_train = x_train.reshape(-1,28*28).astype('float32')/255.0      # Normalization
x_test = x_test.reshape(-1,28*28).astype('float32')/255.0

# Sequential API (very convenient, not very flexible)
model = keras.Sequential(
    [
        layers.Dense(512, activation='relu'),
        layers.Dense(256, activation='relu'),
        layers.Dense(18),
])

model.compile(loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              optimizer = keras.optimizers.Adam(learning_rate=0.001),
              metrics = ["accuracy"])



model.fit(x_train, y_train, batch_size=32, epochs=5, verbose=2)

model.evaluate(x_test, y_test, batch_size=32, verbose=2)
print('Model Summary: ', model.summary())
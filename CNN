import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import tensorflow as tf
import keras
from keras import layers
from keras.datasets import cifar10

# If you face any issue to run the code in GPU...,
physical_devices = tf.config.list_physical_devices('GPU')
try:
  tf.config.experimental.set_memory_growth(physical_devices[0], True)
except:
  pass

(x_train,y_train),(x_test,y_test) = cifar10.load_data()

model = keras.Sequential(
    [
     keras.Input(shape=(32,32,3)),
     layers.conv2D(32,3,padding='valid',activation='relu'),
     layers.MaxPooling2D(pool_size=(2,2)),
     layers.conv2D(64,3,padding='valid',activation='relu'),
     layers.MaxPooling2D(),
     layers.conv2D(128,3,activation='relu'),
     layers.Flatten(),
     layers.Dense(64, activation='relu'),
     layers.Dense(10)
])

model.compile(
    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    optimizer=keras.optimizers.Adam(learning_rate=3e-4),
    metrics=['accuracy']
)

model.fit(x_train, y_train, batch_size=64, epochs=10, verbose=2)
model.evaluate(x_test, y_test, batch_size=64, verbose=2)
print(model.summary())